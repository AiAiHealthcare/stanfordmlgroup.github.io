<!DOCTYPE html><!-- Author: Pranav Rajpurkar 2017--><html><head><meta charset="utf-8"><title>Countdown Regression</title><meta name="description" content="Countdown Regression: Sharp and Calibrated Survival Predictions."><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><meta property="og:image" content="/logo.jpg"><link rel="image_src" type="image/jpeg" href="/logo.jpg"><link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"><link rel="icon" href="/favicon.ico" type="image/x-icon"><link href="/lib/bootstrap/css/bootstrap.min.css" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Catamaran:100,200,300,400,500,600,700,800,900" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Muli" rel="stylesheet"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/lib/simple-line-icons/css/simple-line-icons.css"><link href="/css/theme.css" rel="stylesheet"><link rel="stylesheet" type="text/css" href="/projects/chexnet/css/chexnet.css"><script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script><script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script><script src="/js/analytics.js"></script></head><body><nav class="navbar navbar-default navbar-fixed-top" id="mainNav"><div class="container"><!-- Brand and toggle get grouped for better mobile display--><div class="navbar-header"><a class="navbar-brand page-scroll" href="/">Stanford ML Group</a></div><!-- Collect the nav links, forms, and other content for toggling--></div></nav><section id="header"><div class="container"><div class="row"><div class="col-lg-7"><h1 id="page-title">Countdown Regression: Sharp and Calibrated Survival Predictions.</h1><h2>Anand Avati, Tony Duan, Kenneth Jung, Nigam H. Shah, and Andrew Y. Ng</h2></div></div></div></section><section><div class="container"><div class="row"><h2>A new machine learning approach to make confident and calibrated forecasts of time-to-event (such as mortality).</h2><div class="col-lg-12"><p>Calibrated probabilistic forecasts of time-to-event (such as mortality) can be crucial in healthcare. Calibration means that predicted probabilities match real world frequencies (e.g among all the days that had a rain forecast of 80%, approximately 8 of 10 times it actually rained). Probabilistic forecasts are useful only when they are calibrated, and their usefulness increases with the forecast's confidence (e.g it is less useful to always predict the long term average of rain, though it would be calibrated). The field of meteorology has developed mathematical tools (called CRPS) to increase confidence in weather forecasts while maintaining calibration. We extend these tools to handle partial observations (a.k.a censoring), thus making them suitable for use with time-to-event forecasting. We call this Survival-CRPS, and apply it with a Recurrent Neural Network (RNN) to predict time-to-mortality of millions of patients using their Electronic Health Record (EHR) data.</p><a class="btn btn-lg btn-default" href="https://arxiv.org/abs/1806.08324">Read our paper</a></div></div></div></section><section class="gray"><div class="container"><div class="row"><h2>Two techniques for confident forecasts</h2></div><div class="row"><div class="col-md-5"><p>Maximum Likelihood Estimation (MLE), the most common approach in machine learning, fails to work well for forecasting time to all-cause mortality with EHR data. This is because, in real world EHRs, majority of the patients are alive. In such low prevalence conditions, the mathematical properties of MLE (i.e log-loss) tends to make survival forecasts that can be wildly unreasonable (e.g predicting the expected age-of-death to be many hundreds of years), though technically calibrated. This makes naive MLE based survival predictions practically unusable.</p></div><div class="col-md-7"><img src="/projects/countdown-regression/img/cdr-sharpness.png"></div></div><div class="row"><div class="col-md-12"><p>We present two independent techniques to improve the confidence of predictions in this scenario. First, we use Survival-CRPS in place of MLE. Second, based on the fact that humans generally do not live past 120 years of age, we create Interval Censored variants of both Survival-CRPS and MLE. The two techniques independently, and jointly, improve the quality of survival predictions.</p></div></div></div></section><section><div class="container"><div class="row"><h2>Survival-CRPS: Graphical Intuition</h2></div><div class="row"><div class="col-md-7"><img src="/projects/countdown-regression/img/cdr-crps.png"></div><div class="col-md-5"><p>Survival-CRPS is best understood with the visualization of the Cumulative Distribution Function (CDF) of the forecast. As illustrated in the first picture, the CRPS objective optimizes the forecast distribution to minimize the shaded area around Y, the actual outcome.</p></div></div><div class="row"><div class="col-md-12"><p>The Survival-CRPS is a generalization of this approach, as shown in the next two pictures. It optimizes the forecast distribution to minimize the shaded regions only over those time periods where we are certain that the event (e.g death) has either not yet occured, or has already occurred (e.g the age of the person turns 120 years).</p></div></div></div></section><section class="gray"><div class="container"><div class="row"><div class="h2">Predictions over time with Recurrent Neural Networks</div></div><div class="row"><div class="col-md-5"><p>The RNN architecture is a natural fit for modeling data over time (such as patients making several visits to a hospital). We show that the model learns to make more confident predictions for the same patient given more history. This is illustrated in these pictures of six random patients, where we compare the true time-to-event (red line) with the corresponding forecasts (mean, upper and lower bounds of the 95% prediction interval). The sequential and monotonically decreasing time-to-event in such an RNN model inspires the name Countdown Regression.</p><a class="btn btn-lg btn-default" href="https://arxiv.org/abs/1711.06402">Read our paper</a></div><div class="col-md-7"><img src="/projects/countdown-regression/img/cdr-countdown.png"></div></div></div></section><section class="bg-primary"><div class="container"><div class="row"><div class="col-md-12"><h3>If you have questions about our work,
contact us at:</h3><h4><code>avati@cs.stanford.edu</code></h4></div></div></div></section><footer><div class="container"><div class="row"><div class="col-md-12 text-center"><a href="/"><img src="/img/stanfordmlgrouplogo.svg"></a></div></div></div></footer><script src="/lib/jquery/jquery.min.js"></script><script src="/lib/bootstrap/js/bootstrap.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script><script src="/js/theme.js"></script></body></html>