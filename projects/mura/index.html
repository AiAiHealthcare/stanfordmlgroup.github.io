<!DOCTYPE html><!-- Author: Pranav Rajpurkar 2017--><html><head><meta charset="utf-8"><title>MURA Dataset: Towards Radiologist-Level Abnormality Detection in Musculoskeletal Radiographs</title><meta name="description" content="We introduce MURA, a large dataset of musculoskeletal radiographs containing 40,895 images from 14,982 studies, where each study is manually labeled by radiologists as either normal or abnormal."><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><meta property="og:image" content="/logo.jpg"><link rel="image_src" type="image/jpeg" href="/logo.jpg"><link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"><link rel="icon" href="/favicon.ico" type="image/x-icon"><link href="/lib/bootstrap/css/bootstrap.min.css" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Catamaran:100,200,300,400,500,600,700,800,900" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Muli" rel="stylesheet"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/lib/simple-line-icons/css/simple-line-icons.css"><link href="/css/theme.css" rel="stylesheet"><link rel="stylesheet" type="text/css" href="/projects/mura/css/index.css"><script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script><script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script><script src="/js/analytics.js"></script></head><body><nav class="navbar navbar-default navbar-fixed-top" id="mainNav"><div class="container"><!-- Brand and toggle get grouped for better mobile display--><div class="navbar-header"><a class="navbar-brand page-scroll" href="/">Stanford ML Group</a></div><!-- Collect the nav links, forms, and other content for toggling--></div></nav><section id="header"><div class="container"><div class="row"><div class="col-lg-8"><h1 id="page-title">MURA Dataset: Towards Radiologist-Level Abnormality Detection in Musculoskeletal Radiographs</h1><h2>Pranav Rajpurkar*, Jeremy Irvin*, Aarti Bagul, Daisy Ding, Tony Duan, Hershel Mehta, Brandon Yang, Kaylie Zhu, Dillon Laird, Robyn L. Ball, Curtis Langlotz, Katie Shpanskaya, Matthew P. Lungren, Andrew Ng</h2></div></div></div></section><section><div class="container"><div class="row"><div class="col-md-6"><h2>We introduce MURA, a large dataset of musculoskeletal radiographs containing 40,895 images from 14,982 studies, where each study is manually labeled by radiologists as either normal or abnormal.</h2><p>Large, high-quality datasets have played a critical role in driving progress of fields with deep learning methods. To this end, we introduce one of the largest public radiographic image datasets.</p><p>The MURA abnormality detection task is a binary classification task, where the input is an upper exremity radiograph study --- with each study containing one or more views (images) --- and the expected output is a binary label indicating whether the study is normal or abnormal respectively.</p><ul class="list-unstyled"><li><a class="btn btn-lg btn-default" href="https://arxiv.org/abs/1712.06957">Read our paper</a></li><li><a class="btn btn-lg btn-default" href="https://cs.stanford.edu/group/mlgroup/mura-v1.0.zip" download>Download the data</a></li></ul><p class="small">Instructions to submit your model on the hidden test set coming soon.</p></div><div class="col-md-6"><img src="/projects/mura/img/dataset.svg"></div></div></div></section><section class="gray"><div class="container-fluid"><div class="row"><div class="col-md-4"><img src="/projects/mura/img/pipeline.svg" style="max-height:700px;"></div><div class="col-md-5"><h2>On MURA, we develop a model that uses a 169-layer convolutional neural network to detect and localize abnormalities. </h2><p>The model takes as input one or more views for a study of an upper extremity. On each view, our 169-layer convolutional neural network predicts the probability of abnormality. We compute the overall probability of abnormality for the study by taking the arithmetic mean of the abnormality probabilities output by the network for each image. The model makes the binary prediction of abnormal if the probability of abnormality for the study is greater than 0.5.</p><p>The network uses a Dense Convolutional Network architecture, which connects each layer to every other layer in a feed-forward fashion to make the optimization of deep networks tractable. We replace the final fully connected layer with one that has a single output, after which we apply a sigmoid nonlinearity. We use Class Activation Maps to visualize the parts of the radiograph which contribute most to the model's prediction of abnormality.</p></div><div class="col-md-3"><img class="center" src="/projects/mura/img/MSK-local2.svg"></div></div></div></section><section><div class="container"><div class="row"><div class="col-md-offset-2 col-md-8"><img class="center" src="/projects/mura/img/results.png"><h2>We find that our model achieves performance comparable to that of radiologists.</h2><p>To evaluate models robustly and to get an estimate of radiologist performance, we collected additional labels from board-certified Stanford radiologists on the test set, consisting of 209 musculoskeletal studies. To evaluate radiologists, we compute the F1 score of individual radiologist labels using the majority vote of the labels provided by the other 5 radiologists as ground truth. We similarly evaluate models, by computing the F1 score of the model predictions against each group of 5 radiologists, using the group's majority vote as the ground truth. We report the mean of the resulting 6 F1 scores of the radiologists and the model.</p><p>On finger, hand, and wrist studies, our model's F1 scores are slightly higher than those of radiologists, but not statistically significantly so; on elbow, forearm, humerus, and shoulder studies our model's F1 scores are slightly lower than those of radiologists, but also not statistically significantly so.</p></div></div></div></section><section class="gray"><div class="container"><div class="row"><div class="col-md-7"><h3> Musculoskeletal conditions affect more than 1.7 billion people worldwide, and are the most common cause of severe, long-term pain and disability, with 30 million emergency department visits annually and increasing.
We hope that our dataset can lead to significant advances in medical imaging technologies which can diagnose at the level of experts, towards improving healthcare access in parts of the world where access to skilled radiologists is limited.</h3></div></div></div></section><section class="bg-primary"><div class="container"><div class="row"><div class="col-md-12"><h3>If you have questions about our work,
contact us at:</h3><h4><code>pranavsr@cs.stanford.edu</code> and <code>jirvin16@cs.stanford.edu</code></h4></div></div></div></section><footer><div class="container"><div class="row"><div class="col-md-12 text-center"><a href="/"><img src="/img/stanfordmlgrouplogo.svg"></a></div></div></div></footer><script src="/lib/jquery/jquery.min.js"></script><script src="/lib/bootstrap/js/bootstrap.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script><script src="/js/theme.js"></script></body></html>