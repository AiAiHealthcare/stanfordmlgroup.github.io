<!DOCTYPE html><!-- Author: Pranav Rajpurkar 2017--><html><head><meta charset="utf-8"><title>CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning</title><meta name="description" content="Detecting Pneumonia from Chest X-Rays better than a radiologist."><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><meta property="og:image" content="/logo.jpg"><link rel="image_src" type="image/jpeg" href="/logo.jpg"><link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"><link rel="icon" href="/favicon.ico" type="image/x-icon"><link href="/lib/bootstrap/css/bootstrap.min.css" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Catamaran:100,200,300,400,500,600,700,800,900" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Muli" rel="stylesheet"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/lib/simple-line-icons/css/simple-line-icons.css"><link href="/css/theme.css" rel="stylesheet"><link rel="stylesheet" type="text/css" href="/projects/chexnet/css/chexnet.css"><script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script><script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script><script src="/js/analytics.js"></script></head><body><nav class="navbar navbar-default navbar-fixed-top" id="mainNav"><div class="container"><!-- Brand and toggle get grouped for better mobile display--><div class="navbar-header"><a class="navbar-brand page-scroll" href="/">Stanford ML Group</a></div><!-- Collect the nav links, forms, and other content for toggling--></div></nav><section id="header"><div class="container"><div class="row"><div class="col-lg-8"><h1 id="page-title">CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning</h1><h2>Pranav Rajpurkar*, Jeremy Irvin*, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, Matthew P. Lungren, Andrew Y. Ng</h2></div></div></div></section><section><div class="container"><div class="row"><div class="col-md-7"><h2>We develop an algorithm that can detect pneumonia from chest X-rays at a level exceeding practicing radiologists.</h2><p>Chest X-rays are currently the best available method for diagnosing pneumonia, playing a crucial role in clinical care and epidemiological studies. Pneumonia is responsible for more than 1 million hospitalizations and 50,000 deaths per year in the US alone.</p><a class="btn btn-lg btn-default" href="https://arxiv.org/">Read our paper</a></div></div></div></section><section class="gray"><div class="container"><div class="row"><div class="col-md-7"><img src="/projects/chexnet/img/chex-main.svg" style="max-height:700px;"></div><div class="col-md-5"><h2>Our model, CheXNet, is a 121-layer convolutional neural network that inputs a chest X-ray image and outputs the probability of pneumonia along with a heatmap localizing the areas of the image most indicative of pneumonia. </h2><p>We train CheXNet on the recently released ChestX-ray14 dataset, which contains 112,120 frontal-view chest X-ray images individually labeled with up to 14 different thoracic diseases, including pneumonia. We use dense connections and batch normalization to make the optimization of such a deep network tractable.</p></div></div></div></section><section><div class="container"><div class="row"><div class="col-md-7"><h2>We train on ChestX-ray14, the largest publicly available chest X- ray dataset.</h2><p>The dataset, released by the NIH, contains 112,120 frontal-view X-ray images of 30,805 unique patients, annotated with up to 14 different thoracic pathology labels using NLP methods on radiology reports. We label images that have pneumonia as one of the annotated pathologies as positive examples and label all other images as negative examples for the pneumonia detection task.</p><p>We collected a test set of 420 frontal chest X-rays. Annotations were obtained independently from four practicing radiologists at Stanford University, who were asked to label all 14 pathologies, even though . We then evaluate the performance of an individual radiologist by using the majority vote of the other 3 radiologists as ground truth. Similarly, we evaluate CheXNet using the majority vote of 3 of 4 radiologists, repeated four times to cover all groups of 3.</p></div><div class="col-md-5"><img src="/projects/chexnet/img/chest-example.png"></div></div></div></section><section><div class="container"><div class="row"><div class="col-md-7"><img src="/projects/chexnet/img/roc.png"></div><div class="col-md-5"><h2>We find that the model exceeds the average radiologist performance at the pneumonia detection task on both sensitivity and specificity.</h2><p>ChexNet is tested against radiologists on sensitivity (which measures the proportion of positives that are correctly identified as such) and specificity (which measures the proportion of negatives that are correctly identified as such). A single radiologistâ€™s performance is represented by an orange marker, while the average is represented by green. CheXNet outputs the probability of detecting pneumonia in a Chest X-ray, and the blue curve is generated by varying the thresholds used for the classification boundary. The sensitivity-specificity point for each radiologist and for the average lie below the blue curve, signifying that CheXNet is able to detect pneumonia at a level matching or exceeding radiologists.</p></div></div></div></section><section class="gray"><div class="container"><div class="row"><div class="col-md-7"><h3> With approximately 2 billion procedures per year, chest X-rays are the most common imaging examination tool used in practice, critical for screening, diagnosis, and management of diseases including pneumonia. However, an estimated two thirds of the global population lacks access to radiology diagnostics. With automation at the level of experts, we hope that this technology can improve healthcare delivery and increase access to medical imaging expertise in parts of the world where access to skilled radiologists is limited.</h3><a class="btn btn-lg btn-default" href="">Read our paper</a></div></div></div></section><section class="bg-primary"><div class="container"><div class="row"><div class="col-md-12"><h3>If you have questions about our work,
contact us at:</h3><h4><code>pranavsr@cs.stanford.edu</code> and <code>jirvin16@cs.stanford.edu</code></h4></div></div></div></section><footer><div class="container"><div class="row"><div class="col-md-12 text-center"><a href="/"><img src="/img/stanfordmlgrouplogo.svg"></a></div></div></div></footer><script src="/lib/jquery/jquery.min.js"></script><script src="/lib/bootstrap/js/bootstrap.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script><script src="/js/theme.js"></script></body></html>